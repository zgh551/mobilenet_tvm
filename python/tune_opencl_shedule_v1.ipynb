{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09b1ab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import tvm\n",
    "from tvm import relay, auto_scheduler\n",
    "# import tvm.relay.testing\n",
    "from tvm.contrib import graph_executor\n",
    "from tvm.auto_scheduler.utils import request_remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7717cf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model = onnx.load('../mobilenet/mobilenetv2-7.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae91d41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape_dict:  {'input': (1, 3, 244, 244)}\n"
     ]
    }
   ],
   "source": [
    "input_name = \"input\"\n",
    "input_shape = (1, 3, 244, 244)\n",
    "shape_dict = {input_name: input_shape}\n",
    "print(\"shape_dict: \", shape_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21145b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params = relay.frontend.from_onnx(mobilenet_model, shape_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fce9ea4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: v9h\n",
      "rpc_host: 192.168.105.70:9190\n",
      "log file: mobilenet-NCHW-B1-opencl-C20000-T21-08-13-15-24.json\n"
     ]
    }
   ],
   "source": [
    "# Also replace this with the device key in your tracker\n",
    "device_key = \"v9h\"\n",
    "rpc_host = \"192.168.105.70\"\n",
    "rpc_port = 9190\n",
    "\n",
    "# Define the neural network and compilation target.\n",
    "network = \"mobilenet\"\n",
    "batch_size = 1\n",
    "layout = \"NCHW\"\n",
    "turn_trials = 20000\n",
    "turn_enable = True\n",
    "preload_log_file = True\n",
    "# Set this to True if you use ndk tools for cross compiling\n",
    "use_ndk = False\n",
    "# Path to cross compiler\n",
    "# os.environ[\"TVM_NDK_CC\"] = \"/usr/bin/aarch64-linux-gnu-g++\"\n",
    "target = tvm.target.Target(\"opencl\", host=\"llvm -mtriple=aarch64-linux-gnu\")\n",
    "dtype = \"float32\"\n",
    "log_file = \"%s-%s-B%d-%s-C%s-T%s.json\" % (network, layout, batch_size, target.kind.name, turn_trials, time.strftime('%y-%m-%d-%H-%M',time.localtime(time.time())))\n",
    "print(\"device:\", device_key)\n",
    "print(\"rpc_host: %s:%s\" % (rpc_host, rpc_port))\n",
    "print(\"log file:\", log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de77f45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if layout == 'NHWC':\n",
    "    # convert from NCHW to NHWC\n",
    "    desired_layouts = {'nn.conv2d': ['NHWC', 'default']}\n",
    "\n",
    "    # Convert the layout to NHWC\n",
    "    # RemoveUnunsedFunctions is used to clean up the graph.\n",
    "    seq = tvm.transform.Sequential([relay.transform.RemoveUnusedFunctions(),\n",
    "                                    relay.transform.ConvertLayout(desired_layouts)])\n",
    "\n",
    "    with tvm.transform.PassContext(opt_level=3):\n",
    "        model = seq(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e09cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remote = request_remote(device_key, rpc_host, rpc_port)\n",
    "# dev = remote.cl()\n",
    "# print(\"device_name:\", dev.device_name)\n",
    "# print(\"compute_version:\", dev.compute_version)\n",
    "# print(\"max_clock_rate:\", dev.max_clock_rate)\n",
    "# print(\"multi_processor_count:\", dev.multi_processor_count)\n",
    "# print(\"max_thread_dimensions:\", dev.max_thread_dimensions)\n",
    "# max_shared_memory_per_block = dev.max_shared_memory_per_block\n",
    "# print(\"max_shared_memory_per_block:\", max_shared_memory_per_block)\n",
    "# max_threads_per_block = dev.max_threads_per_block\n",
    "# print(\"max_threads_per_block:\", max_threads_per_block)\n",
    "# warp_size = dev.warp_size\n",
    "# print(\"warp_size: \", warp_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab2a0f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_shared_memory_per_block: 4096\n",
      "max_threads_per_block: 512\n",
      "warp_size:  2\n",
      "max_local_memory_per_block: 4096000\n",
      "max_vthread_extent: 2\n",
      "number of cores: 2\n",
      "vector unit bytes: 16\n",
      "cache line bytes: 64\n",
      "Begin tuning...\n",
      "preload file: mobilenet-NCHW-B1-opencl-C3000-T21-08-11-21-39.json\n",
      "Get devices for measurement successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zgh/.local/share/virtualenvs/ustc-PR_5tIRD/lib/python3.6/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n",
      "-------------------------------------------------\n",
      "|    0 |        2.699 |           0.95 |    128 |\n",
      "|    1 |        0.380 |          -0.00 |    128 |\n",
      "|    2 |        2.040 |          25.83 |    128 |\n",
      "|    3 |        1.381 |          28.50 |    128 |\n",
      "|    4 |        0.330 |           3.92 |    192 |\n",
      "|    5 |        0.814 |          24.37 |    192 |\n",
      "|    6 |        0.954 |          20.63 |    192 |\n",
      "|    7 |        0.561 |          21.03 |    128 |\n",
      "|    8 |        0.582 |           1.33 |    128 |\n",
      "|    9 |        1.242 |          23.15 |    256 |\n",
      "|   10 |        1.111 |          25.53 |    256 |\n",
      "|   11 |        0.580 |           5.34 |    128 |\n",
      "|   12 |        0.633 |          29.85 |    128 |\n",
      "|   13 |        0.469 |           4.41 |    256 |\n",
      "|   14 |        0.577 |          22.32 |    192 |\n",
      "|   15 |        0.454 |          27.80 |    128 |\n",
      "|   16 |        0.308 |          20.45 |    128 |\n",
      "|   17 |        0.717 |           1.44 |    128 |\n",
      "|   18 |        1.142 |          10.83 |    256 |\n",
      "|   19 |        0.685 |          17.33 |    128 |\n",
      "|   20 |        1.854 |           2.09 |    256 |\n",
      "|   21 |        0.719 |          12.36 |    128 |\n",
      "|   22 |        2.518 |           1.15 |    192 |\n",
      "|   23 |        2.510 |          10.89 |    256 |\n",
      "|   24 |        2.200 |          11.77 |    192 |\n",
      "|   25 |        5.286 |           2.13 |    320 |\n",
      "|   26 |        1.477 |          11.67 |    128 |\n",
      "|   27 |        6.064 |           1.24 |    320 |\n",
      "|   28 |        5.107 |           9.79 |    128 |\n",
      "|   29 |        1.346 |          11.50 |    128 |\n",
      "|   30 |        2.779 |           3.60 |    256 |\n",
      "|   31 |        2.930 |           9.26 |    192 |\n",
      "-------------------------------------------------\n",
      "Estimated total latency: 71.241 ms\tTrials: 0\tUsed time : 104 s\tNext ID: 28\t\n",
      "......******\n",
      "......******\n",
      "......******\n",
      "......******\n",
      "....T.T.T***\n",
      "......******\n",
      "......******\n",
      "....."
     ]
    }
   ],
   "source": [
    "if turn_enable:\n",
    "    max_shared_memory_per_block = 4096\n",
    "    print(\"max_shared_memory_per_block:\", max_shared_memory_per_block)\n",
    "    max_threads_per_block = 512\n",
    "    print(\"max_threads_per_block:\", max_threads_per_block)\n",
    "    warp_size = 2\n",
    "    print(\"warp_size: \", warp_size)\n",
    "\n",
    "    # There is no explicit local memory limition\n",
    "    # so we can use INT32_MAX to disable the check on local_memory.\n",
    "    max_local_memory_per_block = 4096000 # INT32_MAX\n",
    "    print(\"max_local_memory_per_block:\", max_local_memory_per_block)\n",
    "\n",
    "    max_vthread_extent = 2 #int(dev.warp_size / 4) if int(dev.warp_size / 4) > 1 else dev.warp_size\n",
    "    print(\"max_vthread_extent:\", max_vthread_extent)\n",
    "\n",
    "    num_cores = 2\n",
    "    print(\"number of cores:\", num_cores)\n",
    "\n",
    "    vector_unit_bytes = 16\n",
    "    print(\"vector unit bytes:\", vector_unit_bytes)\n",
    "\n",
    "    cache_line_bytes = 64\n",
    "    print(\"cache line bytes:\", cache_line_bytes)\n",
    "    \n",
    "    hardware_params = auto_scheduler.HardwareParams(num_cores, vector_unit_bytes, cache_line_bytes,\n",
    "                                                max_shared_memory_per_block, max_local_memory_per_block,\n",
    "                                                max_threads_per_block, max_vthread_extent, warp_size)\n",
    "    \n",
    "    tasks, task_weights = auto_scheduler.extract_tasks(model[\"main\"], params, target, hardware_params=hardware_params)\n",
    "    \n",
    "    print(\"Begin tuning...\")\n",
    "    if preload_log_file:\n",
    "        load_log_file = \"mobilenet-NCHW-B1-opencl-C3000-T21-08-11-21-39.json\"\n",
    "        print(\"preload file:\", load_log_file)\n",
    "        tuner = auto_scheduler.TaskScheduler(tasks, task_weights, load_log_file=load_log_file)\n",
    "    else:\n",
    "        tuner = auto_scheduler.TaskScheduler(tasks, task_weights)\n",
    "\n",
    "    tune_option = auto_scheduler.TuningOptions(\n",
    "        num_measure_trials=turn_trials,  # change this to 20000 to achieve the best performance\n",
    "        builder=auto_scheduler.LocalBuilder(build_func=\"ndk\" if use_ndk else \"default\"),\n",
    "        runner=auto_scheduler.RPCRunner(\n",
    "            device_key, host=rpc_host, port=rpc_port, repeat=3, timeout=50\n",
    "        ),\n",
    "        measure_callbacks=[auto_scheduler.RecordToFile(log_file)],\n",
    "    )\n",
    "\n",
    "    tuner.tune(tune_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede6119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the whole network\n",
    "print(\"Compile...\")\n",
    "# log_file = \"mobilenet-NCHW-B1-opencl-C2800-T21-08-12-19-02.json\"\n",
    "# log_file = \"mobilenet-NCHW-B1-opencl-C3000-T21-08-11-21-39.json\" # 76ms -> opencl\n",
    "print(\"Load File:\", log_file)\n",
    "with auto_scheduler.ApplyHistoryBest(log_file):\n",
    "    with tvm.transform.PassContext(opt_level=3, config={\"relay.backend.use_auto_scheduler\": True}):\n",
    "        lib = relay.build(model, target, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5b4613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph executor\n",
    "print(\"=============== Request Remote ===============\")\n",
    "from tvm.auto_scheduler.utils import request_remote\n",
    "\n",
    "remote = request_remote(device_key, rpc_host, rpc_port)\n",
    "dev = remote.cl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f811024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tvm.contrib import utils, ndk\n",
    "# temp = utils.tempdir()\n",
    "filename = \"deploy_lib.tar\"\n",
    "path_lib = \"./\" + filename\n",
    "# lib.export_library(path_lib, ndk.create_shared)\n",
    "lib.export_library(path_lib)\n",
    "remote.upload(path_lib)\n",
    "loaded_lib = remote.load_module(filename)\n",
    "module = graph_executor.GraphModule(loaded_lib[\"default\"](dev))\n",
    "data = (np.random.uniform(size=input_shape)).astype(dtype)\n",
    "data_tvm = tvm.nd.array(data)\n",
    "module.set_input(input_name, data_tvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5202d9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "print(\"Evaluate inference time cost...\")\n",
    "ftimer = module.module.time_evaluator(\"run\", dev, repeat=3, min_repeat_ms=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe5923",
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_res = np.array(ftimer().results) * 1e3  # convert to millisecond\n",
    "print(\"Mean inference time (std dev): %.2f ms (%.2f ms)\" % (np.mean(prof_res), np.std(prof_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a354d2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
